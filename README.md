# Udacity - Introduction to Machine Learning With TensorFlow

This repository contains some of the exercises and all projects necessary for me to complete the Introduction to Machine Learning with TensorFlow nanodegree by Udacity. There were three main modules/lessons to this module and each are completed using Python:

   * Supervised Learning Module:

      In this module I learned several different machine learning algorithms at a high-level. The ML algorithms that I learned about included: linear regression, decision trees, ensemble methods and naive bayes.

   * Deep Learning Module:

      In this module I learned the fundamentals of how deep neural networks work and how to build a simple DNN from scratch using numpy. I then learned how to use TensorFlow to build DNNs and fit them to training data and evaluate their performance on test data.

   * Unsupervised Learning Module:

      In this module I learned the fundamentals of several unsupervised machine learning algorithms at a high level. Some of the clustering algorithms that  I learned about were: k-means, hierarchical and density based clustering, Gaussian mixture models. In addition I learned about dimensionality reduction: Principal Components Analysis and random projection.

      # Projects

        * ## Project 1

            CharityML is a fictitious charity organization located in the heart of Silicon Valley that was established to provide financial support for people eager to learn machine learning. After nearly 32,000 letters were sent to people in the community, CharityML determined that every donation they received came from someone that was making more than $50,000 annually. To expand their potential donor base, CharityML has decided to send letters to residents of California, but to only those most likely to donate to the charity. With nearly 15 million working Californians, CharityML has brought you on board to help build an algorithm to best identify potential donors and reduce overhead cost of sending mail. Your goal will be evaluate and optimize several different supervised learners to determine which algorithm will provide the highest donation yield while also reducing the total number of letters being sent.

            This project was rather simple. There was no data cleaning required but there were a few data visualizations that were made in order to explore the data and visualize the performance of the ML models.

        * ## Project 2
           This project was composed of two parts: the first part of the project was to train a pre-trained network (MobileNet) on a dataset consisting of images of 102 different types of flowers. A validation set was used during the training process in order monitor the network's performance. Afterwards, a testing set was used in order to evaluate how the trained network performed on unseen data. The trained network was then saved as a .h5 for future use.

           The second part was to use the model saved from part 1 in a python script that would let the user submit a picture of a flower and then have the script return the top **five**  species of flowers that the user submitted image could be. By packaging the saved model from part 1, I effectively built a command line application that let users identify what flowers they had taken a picture of.

           For this project, the biggest skill that I used was of course learning how to use TensorFlow and training the network necessary in order to complete the project. There was no data cleaning required but I did have to make a couple of data visualizations.

      * ## Project 3

          In the words of Udacity:

          In this project, our Bertelsmann partners AZ Direct and Arvato Financial Solutions have provided two datasets one with demographic information about the people of Germany, and one with that same information for customers of a mail-order sales company. Youâ€™ll look at relationships between demographics features, organize the population into clusters, and see how prevalent customers are in each of the segments obtained.

          In order to complete this particular project I had to perform extensive data cleaning (which I enjoy doing) and make data visualizations as well.

# Skills Learned:
   Supervised/Unsupervised machine learning and predictive modeling, building simple data science products
# Skills Used:
   Modeling, data cleaning, data visualization, programming (Python: Pandas, TensorFlow, Maptlotlib/Seaborn, sklearn) and wrestling with TensorFlow.

# Usage
```bash
git clone https://github.com/JWThacker/Udacity_Intro_Machine_Learning_Tensorflow_Nanodegree.git
cd intermediate_python
```
## License (MIT)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
